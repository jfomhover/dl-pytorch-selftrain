{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "Based on the previous step, we'll learn how to save/load the models for resuming training or for applying on data.\n",
    "\n",
    "_Note: we have packages some of the training functions in the `helper.py` module for simplifying the notebook._\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- save and load a model to resume interrupted training\n",
    "- save and load a model for using in deployment\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To benefit from this content, it is preferable to know:\n",
    "- how to train a simple model (see step 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helpers import BasicLabelledDataset\n",
    "from helpers import BasicNeuralNet\n",
    "from helpers import BasicModelTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a model (iris again)\n",
    "\n",
    "This whole section is already known. We'll do the whole IRIS basic neural net thing again. This time we've packaged all steps into a `helper.py` module to get rid of the usual lines of codes.\n",
    "\n",
    "We will just:\n",
    "- load the iris data from scikit-learn\n",
    "- package it in a torch `DatasSet`\n",
    "- create a `Module` class for our model\n",
    "- execute a training loop using autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "\n",
    "np.random.seed(481516)  # just for this notebook to be consistent between runs\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see class in helper.py\n",
    "iris_training_dataset = BasicLabelledDataset(X_train, y_train)\n",
    "iris_testing_dataset = BasicLabelledDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicNeuralNet(\n",
    "    4,  # input has size 4 (attributes)\n",
    "    3,  # output has size 3 (one-hot, 3 classes)\n",
    "    6   # hidden layer (param)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll just apply SGD with a specific criterion (MSELoss). SGD is initialized on the `parameters` of the model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=499]\t epoch_loss=0.263995\t ETA:  0: 0: 0 secs (data=50000/50000, elapsed=13)\r"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# this is a helper class just executing the usual loop (see step 03)\n",
    "trainer = BasicModelTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "epochs=500\n",
    "\n",
    "# executing the training\n",
    "model, loss = trainer.fit(\n",
    "    iris_training_dataset,\n",
    "    epochs=epochs,  # just for trying\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}%\".format(\n",
    "    trainer.test_accuracy(iris_testing_dataset)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Saving the model\n",
    "\n",
    "See [pytorch tutorial on saving and loading models](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
    "> When saving a general checkpoint, to be used for either inference or resuming training, you must save more than just the model’s `state_dict`. It is important to also save the optimizer’s `state_dict`, as this contains buffers and parameters that are updated as the model trains. Other items that you may want to save are the epoch you left off on, the latest recorded training loss, external `torch.nn.Embedding` layers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as models/step-04-model-state-epoch500-loss0.265040.tar\n"
     ]
    }
   ],
   "source": [
    "model_file_path = \"models/step-04-model-state-epoch{}-loss{:2f}.tar\".format(epochs, loss)\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    },\n",
    "    model_file_path\n",
    ")\n",
    "\n",
    "print(\"saved as {}\".format(model_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loading the model for resuming training\n",
    "\n",
    "> To load the items, first initialize the model and optimizer, then load the dictionary locally using `torch.load()`. From here, you can easily access the saved items by simply querying the dictionary as you would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = BasicNeuralNet(\n",
    "    4,  # input has size 4 (attributes)\n",
    "    3,  # output has size 3 (one-hot, 3 classes)\n",
    "    6   # hidden layer (param)\n",
    ")\n",
    "\n",
    "optimizer_2 = torch.optim.SGD(model_2.parameters(), lr=0.01)\n",
    "criterion_2 = torch.nn.MSELoss()\n",
    "\n",
    "# comment/uncomment below to use your own saved model\n",
    "#checkpoint = torch.load(model_file_path)\n",
    "\n",
    "# or simply use the demo\n",
    "checkpoint_2 = torch.load(\"models/step-04-demo-model-state-epoch500-loss0.238621.tar\")\n",
    "\n",
    "# this loads the state dict into the model and optimizer\n",
    "model_2.load_state_dict(checkpoint_2['model_state_dict'])\n",
    "optimizer_2.load_state_dict(checkpoint_2['optimizer_state_dict'])\n",
    "\n",
    "restart_epoch = checkpoint_2['epoch']\n",
    "loss_2 = checkpoint_2['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember that you must call `model.eval()` to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results. If you wish to resuming training, call `model.train()` to ensure these layers are in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicNeuralNet(\n",
       "  (x_to_z): Linear(in_features=4, out_features=6, bias=True)\n",
       "  (z_to_h): Sigmoid()\n",
       "  (h_to_s): Linear(in_features=6, out_features=3, bias=True)\n",
       "  (s_to_y): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use .eval() when loading the model for inference (production)\n",
    "#model_loaded.eval()\n",
    "\n",
    "# use .train() when loading the model for training more (interrupted training?)\n",
    "model_2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now resume the training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import BasicModelTrainer\n",
    "\n",
    "trainer_2 = BasicModelTrainer(\n",
    "    model_2,\n",
    "    optimizer_2,\n",
    "    criterion_2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=9]\t epoch_loss=0.233177\t ETA:  0: 0: 0 secs (data=1000/1000, elapsed=0)\r"
     ]
    }
   ],
   "source": [
    "model_3, loss_3 = trainer_2.fit(\n",
    "    iris_training_dataset,\n",
    "    epochs=10,\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading a model for inference (production)\n",
    "\n",
    "When saving/loading a model for using it in production. You only need to save the state_dict of the model. A call to `model.eval()` will make sure the model is initialized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicNeuralNet(\n",
       "  (x_to_z): Linear(in_features=4, out_features=6, bias=True)\n",
       "  (z_to_h): Sigmoid()\n",
       "  (h_to_s): Linear(in_features=6, out_features=3, bias=True)\n",
       "  (s_to_y): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = BasicNeuralNet(\n",
    "    4,  # input has size 4 (attributes)\n",
    "    3,  # output has size 3 (one-hot, 3 classes)\n",
    "    6   # hidden layer (param)\n",
    ")\n",
    "\n",
    "# comment/uncomment below to use your own saved model\n",
    "#checkpoint_4 = torch.load(model_file_path)\n",
    "\n",
    "# or simply use the demo\n",
    "checkpoint_4 = torch.load(\"models/step-04-demo-model-state-epoch500-loss0.238621.tar\")\n",
    "\n",
    "# this loads the state dict into the model only\n",
    "model_4.load_state_dict(checkpoint_4['model_state_dict'])\n",
    "\n",
    "# use .eval() when loading the model for inference (production)\n",
    "model_4.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this loaded model for evaluating its accuracy on the testing set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.000000\n"
     ]
    }
   ],
   "source": [
    "# batch the testing data as well\n",
    "iris_testing_loader = torch.utils.data.DataLoader(\n",
    "    dataset=iris_testing_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # deactivate autograd during testing\n",
    "    for data in iris_testing_loader:  # iterate on batches\n",
    "        # get testing data batch\n",
    "        inputs, targets = data\n",
    "        \n",
    "        # apply the NN\n",
    "        outputs = model_4(inputs)                 # compute output class tensor\n",
    "        predicted = torch.argmax(outputs, dim=1)  # get argmax of P(y_hat|x)\n",
    "        actual = torch.argmax(targets, dim=1)     # get y\n",
    "\n",
    "        # compute score\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == actual).sum().item()\n",
    "\n",
    "print(\"Accuracy: {:2f}\".format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlselftrain] *",
   "language": "python",
   "name": "conda-env-dlselftrain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
