{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "Based on the historic IRIS dataset, we'll train a simplified neural network like in the 90's.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- define a training and testing `DataSet` class for your model\n",
    "- define a model class (`Module`) for a simple 1 hidden layer NN.\n",
    "- execute the training process (epoch, batches of data)\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To benefit from this content, it is preferable to know:\n",
    "- how Neural Nets work (backprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should know already about the [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). Here's a short description:\n",
    "- 4 numerical attributes\n",
    "- 1 multi-class target (values here in `[0,1,2]` code for flower class).\n",
    "- fairly easily separable classes\n",
    "\n",
    "![Iris dataset scatter plot](https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Iris_dataset_scatterplot.svg/1200px-Iris_dataset_scatterplot.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating classes and instances\n",
    "\n",
    "### 1.1. `DataSet` and `DataLoader`\n",
    "\n",
    "We're getting the data from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're packaging it in a `DataSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# this converts a multi-label column (1D tensor) into one-hot vectors (2D tensor)\n",
    "def one_hot(x, class_count):\n",
    "    return torch.eye(class_count)[x,:]\n",
    "\n",
    "# see examples at https://github.com/utkuozbulak/pytorch-custom-dataset-examples\n",
    "class CustomIrisDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.data_tensor = torch.tensor(self.data).float()\n",
    "        self.target = target\n",
    "        self.target_tensor = one_hot(target, 3)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data_tensor[index], self.target_tensor[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "iris_training_dataset = CustomIrisDataset(X_train, y_train)\n",
    "iris_testing_dataset = CustomIrisDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This custom class will be used by a `DataLoader` to create batches of data to feed into the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will batch the data for you (given you have a DataSet for it)\n",
    "iris_training_loader = torch.utils.data.DataLoader(\n",
    "    dataset=iris_training_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. NN model class as a `Module`\n",
    "\n",
    "The model is defined as a `Module`. It requires the `__init__()` and `forward()` functions.\n",
    "\n",
    "Note: the `backward()` is computed by autograd based on the definition of the `forward()`.\n",
    "\n",
    "![simple neural network model for IRIS data](https://i1.wp.com/www.parallelr.com/wp-content/uploads/2016/02/iris_network.png?resize=456%2C277)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(BasicNeuralNet, self).__init__()\n",
    "        self.x_to_z = torch.nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.z_to_h = torch.nn.Sigmoid()\n",
    "        self.h_to_s = torch.nn.Linear(hidden_size, output_size, bias=True)\n",
    "        self.s_to_y = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.x_to_z(x)  # Linear\n",
    "        h = self.z_to_h(z) # Sigmoid\n",
    "        s = self.h_to_s(h)  # Linear\n",
    "        y = self.s_to_y(s)  # SoftMax\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates an instance with the right sizes\n",
    "# but don't do anything else\n",
    "net = BasicNeuralNet(\n",
    "    4,  # input has size 4 (attributes)\n",
    "    3,  # output has size 3 (one-hot, 3 classes)\n",
    "    6   # hidden layer (param)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "### 2.1. Creating an optimizer\n",
    "\n",
    "We'll just apply SGD with a specific criterion (MSELoss). SGD is initialized on the `parameters` of the `IrisNN` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Iterating on epochs and batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=0]\t loss=2.402\n",
      "[epoch=50]\t loss=2.248\n",
      "[epoch=100]\t loss=2.196\n",
      "[epoch=150]\t loss=2.141\n",
      "[epoch=200]\t loss=2.071\n",
      "[epoch=250]\t loss=1.986\n",
      "[epoch=300]\t loss=1.885\n",
      "[epoch=350]\t loss=1.776\n",
      "[epoch=400]\t loss=1.667\n",
      "[epoch=450]\t loss=1.566\n",
      "[epoch=500]\t loss=1.478\n",
      "[epoch=550]\t loss=1.404\n",
      "[epoch=600]\t loss=1.342\n",
      "[epoch=650]\t loss=1.291\n",
      "[epoch=700]\t loss=1.247\n",
      "[epoch=750]\t loss=1.207\n",
      "[epoch=800]\t loss=1.171\n",
      "[epoch=850]\t loss=1.134\n",
      "[epoch=900]\t loss=1.099\n",
      "[epoch=950]\t loss=1.068\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0  # will store loss for the entire dataset\n",
    "    \n",
    "    for i, data in enumerate(iris_training_loader, 0):  # iterate on batches\n",
    "        # note: data here is a whole batch, a tensor of the data of that batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        attributes, targets = data\n",
    "\n",
    "        # forward prop based on attribute\n",
    "        outputs = net(attributes)  \n",
    "        \n",
    "        # computing loss (NOTE: this is a tensor as well)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # backward prop based on expected value\n",
    "        loss.backward()\n",
    "        \n",
    "        # apply backward prop on parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # just printing for 20 steps\n",
    "    if epoch % (epochs // 20) == 0:\n",
    "        print('[epoch=%d]\\t loss=%.3f' % (epoch, running_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing\n",
    "\n",
    "We'll compute accuracy from scratch here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.000000\n"
     ]
    }
   ],
   "source": [
    "# batch the testing data as well\n",
    "iris_testing_loader = torch.utils.data.DataLoader(\n",
    "    dataset=iris_testing_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # deactivate autograd during testing\n",
    "    for data in iris_testing_loader:  # iterate on batches\n",
    "        # get testing data batch\n",
    "        attributes, targets = data\n",
    "        \n",
    "        # apply the NN\n",
    "        outputs = net(attributes)                 # compute output class tensor\n",
    "        predicted = torch.argmax(outputs, dim=1)  # get argmax of P(y_hat|x)\n",
    "        actual = torch.argmax(targets, dim=1)     # get y\n",
    "\n",
    "        # compute score\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == actual).sum().item()\n",
    "\n",
    "print(\"Accuracy: {:2f}\".format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlselftrain] *",
   "language": "python",
   "name": "conda-env-dlselftrain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
