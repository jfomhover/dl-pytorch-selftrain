{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "Based on the historic IRIS dataset, we'll train a simplified neural network like in the 90's.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- define a training and testing `DataSet` class for your model\n",
    "- define a model class (`Module`) for a simple 1 hidden layer NN.\n",
    "- execute the training process (epoch, batches of data)\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To benefit from this content, it is preferable to know:\n",
    "- how Neural Nets work (backprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should know already about the [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). Here's a short description:\n",
    "- 4 numerical attributes\n",
    "- 1 multi-class target (values here in `[0,1,2]` code for flower class).\n",
    "- fairly easily separable classes\n",
    "\n",
    "![Iris dataset scatter plot](https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Iris_dataset_scatterplot.svg/1200px-Iris_dataset_scatterplot.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating classes and instances\n",
    "\n",
    "### 1.1. `DataSet` and `DataLoader`\n",
    "\n",
    "We're getting the data from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're packaging it in a `DataSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# this converts a multi-label column (1D tensor) into one-hot vectors (2D tensor)\n",
    "def one_hot(x, class_count):\n",
    "    return torch.eye(class_count)[x,:]\n",
    "\n",
    "# see examples at https://github.com/utkuozbulak/pytorch-custom-dataset-examples\n",
    "class BasicLabelledDataset(Dataset):\n",
    "    def __init__(self, inputs_array, targets_array):\n",
    "        self.inputs_array = inputs_array # numpy\n",
    "        self.inputs_tensor = torch.tensor(self.inputs_array).float()\n",
    "        self.targets_array = targets_array # numpy\n",
    "        self.class_count = len(np.unique(targets_array))\n",
    "        if self.class_count > 2:\n",
    "            self.targets_tensor = one_hot(self.targets_array, self.class_count)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.inputs_tensor[index], self.targets_tensor[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets_array)\n",
    "\n",
    "iris_training_dataset = BasicLabelledDataset(X_train, y_train)\n",
    "iris_testing_dataset = BasicLabelledDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This custom class will be used by a `DataLoader` to create batches of data to feed into the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will batch the data for you (given you have a DataSet for it)\n",
    "iris_training_loader = torch.utils.data.DataLoader(\n",
    "    dataset=iris_training_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. NN model class as a `Module`\n",
    "\n",
    "The model is defined as a `Module`. It requires the `__init__()` and `forward()` functions.\n",
    "\n",
    "Note: the `backward()` is computed by autograd based on the definition of the `forward()`.\n",
    "\n",
    "![simple neural network model for IRIS data](https://i1.wp.com/www.parallelr.com/wp-content/uploads/2016/02/iris_network.png?resize=456%2C277)\n",
    "\n",
    "_Note: see at the end of this notebook for a **simplification of this model** definition using `Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(BasicNeuralNet, self).__init__()\n",
    "        self.x_to_z = torch.nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.z_to_h = torch.nn.Sigmoid()\n",
    "        self.h_to_s = torch.nn.Linear(hidden_size, output_size, bias=True)\n",
    "        self.s_to_y = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.x_to_z(x)  # Linear\n",
    "        h = self.z_to_h(z) # Sigmoid\n",
    "        s = self.h_to_s(h)  # Linear\n",
    "        y = self.s_to_y(s)  # SoftMax\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates an instance with the right sizes\n",
    "# but don't do anything else\n",
    "model = BasicNeuralNet(\n",
    "    4,  # input has size 4 (attributes)\n",
    "    3,  # output has size 3 (one-hot, 3 classes)\n",
    "    6   # hidden layer (param)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "### 2.1. Creating an optimizer\n",
    "\n",
    "We'll just apply SGD with a specific criterion (MSELoss). SGD is initialized on the `parameters` of the `IrisNN` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Iterating on epochs and batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=0]\t loss=2.343\n",
      "[epoch=50]\t loss=1.575\n",
      "[epoch=100]\t loss=1.120\n",
      "[epoch=150]\t loss=0.887\n",
      "[epoch=200]\t loss=0.632\n",
      "[epoch=250]\t loss=0.435\n",
      "[epoch=300]\t loss=0.318\n",
      "[epoch=350]\t loss=0.263\n",
      "[epoch=400]\t loss=0.208\n",
      "[epoch=450]\t loss=0.175\n",
      "[epoch=500]\t loss=0.159\n",
      "[epoch=550]\t loss=0.138\n",
      "[epoch=600]\t loss=0.124\n",
      "[epoch=650]\t loss=0.113\n",
      "[epoch=700]\t loss=0.111\n",
      "[epoch=750]\t loss=0.099\n",
      "[epoch=800]\t loss=0.097\n",
      "[epoch=850]\t loss=0.090\n",
      "[epoch=900]\t loss=0.081\n",
      "[epoch=950]\t loss=0.084\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0  # will store loss for the entire dataset\n",
    "    \n",
    "    for i, data in enumerate(iris_training_loader, 0):  # iterate on batches\n",
    "        # note: data here is a whole batch, a tensor of the data of that batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, targets = data\n",
    "\n",
    "        # forward prop based on attribute\n",
    "        outputs = model(inputs)  \n",
    "        \n",
    "        # computing loss (NOTE: this is a tensor as well)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # backward prop based on expected value\n",
    "        loss.backward()\n",
    "        \n",
    "        # apply backward prop on parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # just printing for 20 steps\n",
    "    if epoch % (epochs // 20) == 0:\n",
    "        print('[epoch=%d]\\t loss=%.3f' % (epoch, running_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing\n",
    "\n",
    "We'll compute accuracy from scratch here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.000000\n"
     ]
    }
   ],
   "source": [
    "# batch the testing data as well\n",
    "iris_testing_loader = torch.utils.data.DataLoader(\n",
    "    dataset=iris_testing_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # deactivate autograd during testing\n",
    "    for data in iris_testing_loader:  # iterate on batches\n",
    "        # get testing data batch\n",
    "        inputs, targets = data\n",
    "        \n",
    "        # apply the NN\n",
    "        outputs = model(inputs)                 # compute output class tensor\n",
    "        predicted = torch.argmax(outputs, dim=1)  # get argmax of P(y_hat|x)\n",
    "        actual = torch.argmax(targets, dim=1)     # get y\n",
    "\n",
    "        # compute score\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == actual).sum().item()\n",
    "\n",
    "print(\"Accuracy: {:2f}\".format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "The definition of the model only consists in a sequence of layers. Fairly simple. There's a class for that, so you don't need to define your own class: `Sequential`. You can try again from step 2 with this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4  # input has size 4 (attributes)\n",
    "output_size = 3  # output has size 3 (one-hot, 3 classes)\n",
    "hidden_size = 6   # hidden layer (param)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_size, hidden_size, bias=True),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hidden_size, output_size, bias=True),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlselftrain] *",
   "language": "python",
   "name": "conda-env-dlselftrain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
